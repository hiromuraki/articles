## Linux

### 配置 Docker 环境

**安装 Docker**

> 见 Docker 相关

**配置容器 CUDA 环境**

> 见 Docker 相关

### 创建 Docker 文件

**Dockerfile**

```dockerfile
FROM localai/localai:latest-gpu-nvidia-cuda-12
```

**docker-compose.yml**

```yml
name: local-ai-service

services:
    main:
        build: .
        ports:
            - "8080:8080/tcp"
        environment:
            - HF_ENDPOINT=https://hf-mirror.com
        volumes:
            - type: bind
              source: $USER_LOCAL_SHARE/localai/models/
              target: /models
              read_only: false
        runtime: nvidia
```

### 启动服务

```bash
docker compose up --build
```
